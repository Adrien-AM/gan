# -*- coding: utf-8 -*-
"""GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lRlTXY5Qo2f-YY4Egj_L4nt-TNcfi5mW
"""

import os
# Disable tensorflow warnings
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# %tensorflow_version 2.xs
import tensorflow as tf
import sys
import numpy as np
import matplotlib.pyplot as plt
from keras.layers import (BatchNormalization, Conv2D, Dense, LeakyReLU, ReLU, Dropout, Flatten,
                          Reshape)
# Commented out IPython magic to ensure Python compatibility.
from keras.layers.convolutional import Conv2DTranspose
from keras.models import Sequential, load_model
from keras.initializers.initializers_v2 import RandomNormal 
from keras.optimizer_v2 import adam
from keras.optimizers import RMSProp
from keras.losses import BinaryCrossentropy
from plot_keras_history import show_history

from gan import GAN, GANMonitor, BATCH_SIZE
from data_loaders import IMAGE_SIZE, SIDE, CHANNELS
import data_loaders as loader

# Numpy functions for tensorflow
from tensorflow.python.ops.numpy_ops import np_config
np_config.enable_numpy_behavior()

INITIAL_DIM = 100
DATA_SIZE = 2000

def wasserstein_loss(y_true, y_pred):
    return keras.backend.mean(y_true * y_pred)

def get_generator_v2():
    generator = Sequential(name="generator")

    weight_initializer = RandomNormal(0, 0.02)
    kernel_size = 5

    first_layer_dim = int(SIDE / 8)

    # Image must be 28x28 -> 28=7*2*2, so 2 conv layers with 7 as base dim
    generator.add(Dense(first_layer_dim * first_layer_dim * 128, input_dim=INITIAL_DIM))
    generator.add(BatchNormalization())
    generator.add(ReLU(0.2))

    generator.add(Reshape((first_layer_dim, first_layer_dim, 128)))

    generator.add(Conv2DTranspose(filters=64, kernel_size=kernel_size, strides=2, padding="same", kernel_initializer=weight_initializer))
    generator.add(BatchNormalization())
    generator.add(ReLU(0.2))

    generator.add(Conv2DTranspose(filters=256, kernel_size=kernel_size, strides=2, padding="same", kernel_initializer=weight_initializer))
    generator.add(BatchNormalization())
    generator.add(ReLU(0.2))

    generator.add(Conv2DTranspose(filters=128, kernel_size=kernel_size, strides=2, padding="same", kernel_initializer=weight_initializer))
    generator.add(BatchNormalization())
    generator.add(ReLU(0.2))

    generator.add(Conv2D(filters=CHANNELS, kernel_size=kernel_size, padding="same", activation="tanh"))
    
    return generator

def get_discriminator_v2():
    discriminator = Sequential(name="discriminator")

    kernel_size = 5

    discriminator.add(Conv2D(filters=64, kernel_size=kernel_size, strides=2, padding="same", input_shape=(SIDE, SIDE, CHANNELS)))
    discriminator.add(BatchNormalization())
    discriminator.add(LeakyReLU(0.2))

    discriminator.add(Conv2D(filters=128, kernel_size=kernel_size, strides=2, padding="same"))
    discriminator.add(BatchNormalization())
    discriminator.add(LeakyReLU(0.2))

    discriminator.add(Conv2D(filters=128, kernel_size=kernel_size, strides=2, padding="same"))
    discriminator.add(BatchNormalization())
    discriminator.add(LeakyReLU(0.2))    

    discriminator.add(Flatten())
    discriminator.add(Dropout(0.3))

    discriminator.add(Dense(1, activation="linear"))

    return discriminator

def train_v2(epochs, data):
    discriminator = get_discriminator_v2()
    generator = get_generator_v2()

    if "-v" in sys.argv:
        discriminator.summary()
        generator.summary()
    LR = 0.0001

    gan = GAN(disc=discriminator, gen=generator, initial=INITIAL_DIM, clip_value=0.01)
    gan.compile(
        d_optimizer=RMSProp(LR),
        g_optimizer=RMSProp(LR),
        loss_function=wasserstein_loss()
    )

    history = gan.fit(x=data, epochs=epochs, batch_size=BATCH_SIZE, callbacks=[GANMonitor(num_img=4, initial=INITIAL_DIM)])
    return gan, history

def generate_images(n, generator, discriminator):
    # Generate some pictures from random noise
    initial = np.random.normal(size=[n, INITIAL_DIM])
    pics = generator.predict(initial)
    # Check what discriminator says
    is_good = discriminator.predict(pics)

    pics = pics.reshape((n, SIDE, SIDE, CHANNELS))

    fig = plt.figure()
    for i in range(n):
        fig.add_subplot(1, n, i+1, title="Discrim : %f" % is_good[i])
        plt.imshow(pics[i], interpolation='nearest')
    plt.show(block=True)


def show_data(data, n=3):
    pics = np.array([data[np.random.randint(data.shape[0])] for _ in range(n)])
    pics = pics.reshape((n, SIDE, SIDE, CHANNELS))

    fig = plt.figure()
    for i in range(n):
        fig.add_subplot(1, n, i+1)
        plt.imshow(pics[i], interpolation='nearest')
    plt.show(block=True)


def test_discriminator(data, discriminator, generator, n=3):
    pics = np.array([data[np.random.randint(data.shape[0])] for _ in range(n)])
    prediction = discriminator.predict(pics)
    # Should be 1
    print("Average prediction error for real data : ", np.average(abs(prediction-1)))

    fakes = np.random.rand(n, SIDE, SIDE)
    prediction = discriminator.predict(fakes)
    # Should be 0
    print("Average prediction error for random fakes : ", np.average(prediction))

    generated = generator.predict(np.random.normal(size=(n, INITIAL_DIM)))
    prediction = discriminator.predict(generated)
    # Should be 0
    print("Average prediction error for random generated : ", np.average(prediction))

if __name__ == "__main__":
    print("Usage : \n -n to use existing GAN\n -v to display NN layers")
    epochs = 50

    data = loader.load_landscapes_data(DATA_SIZE)
    
    new = "-n" not in sys.argv

    if new:
        print("Creating new GAN from scratch")
        gan, history = train_v2(epochs, data)
    else:
        print("Using old discriminator and generator")
        try:
            generator = load_model("last_generator.h5")
            discriminator = load_model("last_discriminator.h5")
        except IOError:
            print("Error loading files. Check last_generator.h5 and last_discriminator.h5 exist in current dir.")
            exit(1)

        gan = GAN(disc=discriminator, gen=generator, initial=INITIAL_DIM)

    generate_images(4, gan.generator, gan.discriminator)
    #show_data(data)
    if new:
        show_history(history)
        plt.show()

    if input("Save generator ? ([y]/n)") != "n":
        gan.generator.save("last_generator.h5")
    if input("Save discriminator ? ([y]/n)") != "n":
        gan.discriminator.save("last_discriminator.h5")

    exit(0)

 
